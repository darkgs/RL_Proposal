%지금까지 우리는 본 프로젝트에서 진행했던 내용에 대해 살펴보았다.
%해당 프로젝트를 진행하면서 굉장히 많은 어려움이 존재했다. 
%모델을 다양한 방식으로 수정하고 추가 작업을 진행하여도 성능이 좀처럼 향상되지 않았다.
%따라서 프로젝트 초반에 목표로 정했던 가능한 빠른 시간안에 완주하는 것은 정말 쉽지 않았고, 완주를 하는 것조차 굉장히 어려운 문제였다는 것을 깨달았다.
%
%비록 프로젝트 초반에 설정했던 목표는 달성하지 못했지만 슈퍼 마리오 브라더스 게임을 통해 강화학습을 실제로 구현하고 구현에 필요한 기법들을 서베이하며 강화학습에 대해 많은 것들을 배울 수 있는 기회가 되었다.

본 프로젝트에서 우리는 슈퍼 마리오 브라더스 게임을 DQN 기반의 강화학습 모델로 play할 수 있는 프로그램을 개발 하였다.
기존 아타리 게임등에서 좋은 성능을 보인다고 알려진 DQN을 기반으로 마리오 게임을 좀 더 잘 이해할 수 있도록 화면을 나눠서 feature를 추출하는 \sdqnname을 제안하였고, 더 나아가 attention network를 추가한 \sadqnname을 통해 성능 향상을 도모하였다.
하지만 강화 학습의 특징인 수 많은 hyper parameter들 (CNN 네트워크 구성, replay memory 관련 parameter, optimizer 관련 parameter, 그리고 reward 함수)과 긴 학습시간으로 인해 최적의 세팅과 결과를 얻어내는 데에는 부족한 점이 있었다.
때문에 프로젝트 초반에 설정하였던 목표인 사람보다 빠른 시간내에 완주는 달성하지 못하였다.
하지만 사람의 동작에 따른 intuition인 화면 분할이나 일부 부분에 집중하는 방법을 통해서 일반적인 DQN보다 높은 성능을 얻을 수 있었다는 점은 고무적이었다.

